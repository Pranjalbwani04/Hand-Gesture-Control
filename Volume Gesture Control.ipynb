{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8159606",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59010a27",
   "metadata": {},
   "source": [
    "#### interact with the Windows Core Audio APIs for managing audio devices and audio sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c695d77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycaw in c:\\users\\1810v\\projects\\volume gesture control\\.venv\\lib\\site-packages (20240210)\n",
      "Requirement already satisfied: comtypes in c:\\users\\1810v\\projects\\volume gesture control\\.venv\\lib\\site-packages (from pycaw) (1.4.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\1810v\\projects\\volume gesture control\\.venv\\lib\\site-packages (from pycaw) (6.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pycaw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eee298a",
   "metadata": {},
   "source": [
    "#### cv2 for OpenCV functions\n",
    "\n",
    "#### mediapipe for media processing tasks\n",
    "\n",
    "#### math and time for mathematical operations and time-related functions\n",
    "\n",
    "#### numpy for numerical operations\n",
    "\n",
    "#### ctypes and comtypes for working with Windows COM interfaces\n",
    "\n",
    "#### pycaw for audio endpoint volume control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2c4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d9945",
   "metadata": {},
   "source": [
    "This `HandDetector` class utilizes MediaPipe and OpenCV to detect and track hand landmarks in an image, draw landmarks, determine hand orientation (left/right), identify which fingers are up, and calculate distances between specific hand landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2acc7b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HandDetector:\n",
    "\n",
    "    '''\n",
    "\n",
    "#### 1. What is the function of this code?\n",
    "\n",
    "This code initializes the `HandDetector` class, which is used for detecting and tracking hands in images or videos.\n",
    "\n",
    "#### 2. What is the input?\n",
    "\n",
    "The input parameters are:\n",
    "- `mode` (default: `False`): Whether to use static mode.\n",
    "- `maxHands` (default: `2`): Maximum number of hands to detect.\n",
    "- `detectionCon` (default: `0.5`): Minimum confidence for hand detection.\n",
    "- `minTrackCon` (default: `0.5`): Minimum confidence for hand tracking.\n",
    "\n",
    "#### 3. What is the output?\n",
    "\n",
    "The output is an initialized `HandDetector` object with attributes:\n",
    "- `mode`, `maxHands`, `detectionCon`, `minTrackCon`: Set to the input values.\n",
    "- `mpHands`, `hands`, `mpDraw`: MediaPipe modules for hand detection and drawing.\n",
    "- `tipIds`: Indices of finger tips.\n",
    "- `fingers`, `lmList`: Empty lists for finger states and landmarks.'''\n",
    "\n",
    "    def __init__(self, mode=False, maxHands=2, detectionCon=0.5, minTrackCon=0.5):\n",
    "\n",
    "        self.mode = mode\n",
    "        self.maxHands = maxHands\n",
    "        self.detectionCon = detectionCon\n",
    "        self.minTrackCon = minTrackCon\n",
    "\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(self.mode, self.maxHands, self.detectionCon, self.minTrackCon)\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "        self.tipIds = [4, 8, 12, 16, 20]\n",
    "        self.fingers = []\n",
    "        self.lmList = []\n",
    "\n",
    "        \n",
    "\n",
    "    '''\n",
    "\n",
    "1. **Function Purpose**:\n",
    "   - Detects hands in an image and optionally draws landmarks.\n",
    "\n",
    "2. **Inputs**:\n",
    "   - `img`: Image in BGR format.\n",
    "   - `draw` (bool, default=True): Whether to draw landmarks.\n",
    "\n",
    "3. **Output**:\n",
    "   - The input image with landmarks drawn if hands are detected and `draw` is True.'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def findHands(self, img, draw=True):\n",
    "\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB)\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)\n",
    "        return img\n",
    "    \n",
    "    '''### 1. What is the function of this code?\n",
    "The `findPosition` function locates hand landmarks in an image, calculates their coordinates, optionally draws them, and finds the hand's bounding box.\n",
    "\n",
    "### 2. What is the input?\n",
    "The inputs are:\n",
    "- `img`: The image with the hand.\n",
    "- `handNo` (default 0): The hand to process if there are multiple.\n",
    "- `draw` (default True): Whether to draw the landmarks and bounding box.\n",
    "\n",
    "### 3. What is the output?\n",
    "The outputs are:\n",
    "- `self.lmList`: A list of coordinates for each hand landmark.\n",
    "- `bboxInfo`: Information about the bounding box, including its coordinates, size, and center.'''\n",
    "\n",
    "    def findPosition(self, img, handNo=0, draw=True):\n",
    "\n",
    "        xList = []\n",
    "        yList = []\n",
    "        bbox = []\n",
    "        bboxInfo = []\n",
    "        self.lmList = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "                h, w, c = img.shape\n",
    "                px, py = int(lm.x * w), int(lm.y * h)\n",
    "                xList.append(px)\n",
    "                yList.append(py)\n",
    "                self.lmList.append([px, py])\n",
    "                if draw:\n",
    "                    cv2.circle(img, (px, py), 5, (255, 0, 255), cv2.FILLED)\n",
    "            xmin, xmax = min(xList), max(xList)\n",
    "            ymin, ymax = min(yList), max(yList)\n",
    "            boxW, boxH = xmax - xmin, ymax - ymin\n",
    "            bbox = xmin, ymin, boxW, boxH\n",
    "            cx, cy = bbox[0] + (bbox[2] // 2), \\\n",
    "                     bbox[1] + (bbox[3] // 2)\n",
    "            bboxInfo = {\"id\": id, \"bbox\": bbox, \"center\": (cx, cy)}\n",
    "\n",
    "            if draw:\n",
    "                cv2.rectangle(img, (bbox[0] - 20, bbox[1] - 20), (bbox[0] + bbox[2] + 20, bbox[1] + bbox[3] + 20),\n",
    "                              (0, 255, 0), 2)\n",
    "\n",
    "        return self.lmList, bboxInfo\n",
    "    \n",
    "    '''\n",
    "\n",
    "1. **Function**: The `fingersUp` function checks which fingers are raised on a detected hand. It uses finger landmark positions to determine if each finger is extended or not, returning a list of their states.\n",
    "\n",
    "2. **Input**: The function uses `self.results.multi_hand_landmarks` (detected hand landmarks) and `self.lmList` (specific hand landmark positions), set by the `findHands` and `findPosition` methods.\n",
    "\n",
    "3. **Output**: The function returns a list called `fingers` with five elements. Each element is 1 (finger raised) or 0 (finger not raised), in the order: thumb, index, middle, ring, and little finger.\n",
    "\n",
    "- `myHandType = self.handType()`: Checks if the hand is right or left.\n",
    "- Thumb's state: Checked by x-coordinate of its landmarks.\n",
    "- Other fingers' states: Checked by y-coordinate of their landmarks.\n",
    "- Returns the `fingers` list showing which fingers are up.'''\n",
    "\n",
    "    def fingersUp(self):\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHandType = self.handType()\n",
    "            fingers = []\n",
    "            # Thumb\n",
    "            if myHandType == \"Right\":\n",
    "                if self.lmList[self.tipIds[0]][0] > self.lmList[self.tipIds[0] - 1][0]:\n",
    "                    fingers.append(1)\n",
    "                else:\n",
    "                    fingers.append(0)\n",
    "            else:\n",
    "                if self.lmList[self.tipIds[0]][0] < self.lmList[self.tipIds[0] - 1][0]:\n",
    "                    fingers.append(1)\n",
    "                else:\n",
    "                    fingers.append(0)\n",
    "\n",
    "            # 4 Fingers\n",
    "            for id in range(1, 5):\n",
    "                if self.lmList[self.tipIds[id]][1] < self.lmList[self.tipIds[id] - 2][1]:\n",
    "                    fingers.append(1)\n",
    "                else:\n",
    "                    fingers.append(0)\n",
    "        return fingers\n",
    "    \n",
    "    '''\n",
    "\n",
    "#### 1. What is the function of this code?\n",
    "\n",
    "The `findDistance` method calculates the Euclidean distance between two points (landmarks) on a detected hand and optionally draws visual indicators on the input image. This is useful for various hand gesture recognition tasks, such as measuring the distance between fingertips.\n",
    "\n",
    "#### 2. What is the input?\n",
    "\n",
    "The inputs to the `findDistance` method are:\n",
    "- `p1` and `p2`: Indices of the landmarks on the hand whose distance is to be calculated.\n",
    "- `img`: The image in which the hand landmarks are detected and where the visual indicators (if `draw` is `True`) will be drawn.\n",
    "- `draw`: A boolean flag indicating whether to draw visual indicators on the image. The default value is `True`.\n",
    "\n",
    "#### 3. What is the output?\n",
    "\n",
    "The outputs of the `findDistance` method are:\n",
    "- `length`: The Euclidean distance between the two specified landmarks.\n",
    "- `img`: The input image with visual indicators drawn (if `draw` is `True`).\n",
    "- A list containing the coordinates of the two specified landmarks and the midpoint between them in the format `[x1, y1, x2, y2, cx, cy]`.\n",
    "\n",
    "### Detailed Steps\n",
    "\n",
    "1. **Checking for Hand Landmarks**:\n",
    "   - The method first checks if there are detected hand landmarks (`self.results.multi_hand_landmarks`).\n",
    "\n",
    "2. **Extracting Coordinates**:\n",
    "   - It extracts the coordinates `(x1, y1)` and `(x2, y2)` of the two specified landmarks (`p1` and `p2`) from `self.lmList`.\n",
    "\n",
    "3. **Calculating Midpoint**:\n",
    "   - It calculates the midpoint `(cx, cy)` between the two landmarks.\n",
    "\n",
    "4. **Drawing Visual Indicators** (if `draw` is `True`):\n",
    "   - Circles are drawn at the two landmarks and the midpoint.\n",
    "   - A line is drawn connecting the two landmarks.\n",
    "\n",
    "5. **Calculating Distance**:\n",
    "   - The Euclidean distance between the two landmarks is calculated using the `math.hypot` function.\n",
    "\n",
    "6. **Returning Results**:\n",
    "   - The method returns the calculated distance, the image with visual indicators, and the coordinates of the landmarks and their midpoint.'''\n",
    "\n",
    "    def findDistance(self, p1, p2, img, draw=True):\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            x1, y1 = self.lmList[p1][0], self.lmList[p1][1]\n",
    "            x2, y2 = self.lmList[p2][0], self.lmList[p2][1]\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "            if draw:\n",
    "                cv2.circle(img, (x1, y1), 15, (255, 0, 255), cv2.FILLED)\n",
    "                cv2.circle(img, (x2, y2), 15, (255, 0, 255), cv2.FILLED)\n",
    "                cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "                cv2.circle(img, (cx, cy), 15, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "            length = math.hypot(x2 - x1, y2 - y1)\n",
    "            return length, img, [x1, y1, x2, y2, cx, cy]\n",
    "\n",
    "            '''### Simplified Explanation\n",
    "\n",
    "1. **What is the function of this code?**\n",
    "   - The `handType` method checks if the detected hand is right or left by comparing the x-coordinates of landmarks 5 and 17.\n",
    "\n",
    "2. **What is the input?**\n",
    "   - It doesn't take any inputs directly. It uses the internal data (`self.results.multi_hand_landmarks` and `self.lmList`) set by other methods.\n",
    "\n",
    "3. **What is the output?**\n",
    "   - It returns either \"Right\" or \"Left\" based on the hand detected.'''\n",
    "        \n",
    "\n",
    "\n",
    "    def handType(self):\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            if self.lmList[17][0] < self.lmList[5][0]:\n",
    "                return \"Right\"\n",
    "            else:\n",
    "                return \"Left\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb4176d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. What is the function of this code?\n",
    "This code captures video from the webcam and uses hand detection to control the system volume based on the distance between the thumb and index finger. It tracks the hand in real-time and adjusts the volume accordingly. Additionally, it displays the video feed with visual feedback on the hand detection and volume level.\n",
    "\n",
    "2. What is the input?\n",
    "The primary input for this code is the video stream from the webcam (typically the default camera on the computer, indicated by cv2.VideoCapture(0)). The code also takes input from the detected positions of the hand landmarks to determine the distance between the thumb and index finger.\n",
    "\n",
    "3. What is the output?\n",
    "The output of this code includes:\n",
    "\n",
    "Video Display: A real-time video feed is shown in a window titled \"hands\". This feed includes visual annotations such as the hand landmarks, distance indicators, volume bar, and FPS (frames per second).\n",
    "Volume Control: The system volume is adjusted based on the distance between the thumb and index finger. This change is also visually represented by a volume bar and percentage on the video feed.\n",
    "Visual Feedback: Circles and rectangles are drawn on the video to indicate detected hand positions and the volume level bar.'''\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, 1280)\n",
    "    cap.set(4, 720)\n",
    "    pTime = 0\n",
    "    detector = HandDetector(detectionCon=0)\n",
    "    colorR = (255, 0, 255)\n",
    "    devices = AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "    volRange = volume.GetVolumeRange()\n",
    "    minVol = volRange[0]\n",
    "    maxVol = volRange[1]\n",
    "    vol = 0\n",
    "    volBar = 400\n",
    "    volPer = 0\n",
    "\n",
    "    cx, cy, w, h = 100, 100, 200, 200\n",
    "\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        img = cv2.flip(img, 1)\n",
    "        img = detector.findHands(img)\n",
    "        lmList, _ = detector.findPosition(img)\n",
    "\n",
    "        if lmList:\n",
    "            length, _, _ = detector.findDistance(4, 8, img)\n",
    "            cursor = lmList[8]\n",
    "\n",
    "            vol = np.interp(length, [50, 300], [minVol, maxVol])\n",
    "            volBar = np.interp(length, [50, 300], [400, 150])\n",
    "            volPer = np.interp(length, [50, 300], [0, 100])\n",
    "            volume.SetMasterVolumeLevel(vol, None)\n",
    "            if length < 50:\n",
    "                cv2.circle(img, (cursor[0], cursor[1]), 15, (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "            # Draw the volume bar\n",
    "            cv2.rectangle(img, (50, 150), (85, 400), (255, 0, 0), 3)\n",
    "            cv2.rectangle(img, (50, int(volBar)), (85, 400), (255, 0, 0), cv2.FILLED)\n",
    "            cv2.putText(img, f'{int(volPer)} %', (40, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 3)\n",
    "\n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "\n",
    "        cv2.putText(img, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 3)\n",
    "        cv2.imshow(\"hands\", img)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
